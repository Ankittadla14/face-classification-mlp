Face Recognition using MLPs (Baseline vs DeepNN)

This repository explores face recognition using Multi-Layer Perceptrons (MLPs) implemented in PyTorch.
It compares a baseline shallow MLP with a deeper network (BN + Dropout) to evaluate improvements in accuracy and generalization.

ðŸ“‚ Repository Structure
.
â”œâ”€â”€ facenn_baseline.ipynb   # Baseline MLP (simpler architecture)
â”œâ”€â”€ facenn_deepnn.ipynb     # Deeper MLP with BN + Dropout (recommended)
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ .gitignore              # Ignore unnecessary files
â””â”€â”€ README_face.md          # Project overview (this file)

ðŸ“Š Dataset

Dataset used: face_all.pickle (features + labels)

Size: >25MB (not committed due to GitHub limits).

Download it from Google Drive: ðŸ“¥ Download face_all.pickle

After downloading, place it in the project root folder (same directory as the notebooks):

project-root/
    facenn_baseline.ipynb
    facenn_deepnn.ipynb
    face_all.pickle   <-- place here

âš™ï¸ Installation

Create a virtual environment and install dependencies:

pip install -r requirements.txt

ðŸš€ Running the Notebooks

Run facenn_baseline.ipynb â†’ trains a 2-layer MLP

Run facenn_deepnn.ipynb â†’ trains a deeper MLP with BN + Dropout

Both notebooks load face_all.pickle automatically if present in the same folder.

ðŸ“ Results

Baseline MLP: ~80â€“85% accuracy

Deep MLP (BN + Dropout): ~88â€“90% accuracy

ðŸ“Œ Notes

.pt model files (saved weights) are not included. Train the notebooks to generate them.

The dataset (face_all.pickle) must be manually downloaded before running.
